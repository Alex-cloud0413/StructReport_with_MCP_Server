#!/usr/bin/env python3
# æ‰¹é‡å¤„ç†ç¤ºä¾‹æ•°æ®
import sqlite3
import pandas as pd
import json
import re
from datetime import datetime
from typing import Dict

def extract_with_rules(text: str) -> Dict:
    """ä½¿ç”¨è§„åˆ™å’Œæ­£åˆ™è¡¨è¾¾å¼æå–æ•°æ®"""
    result = {
        "driver_name": None,
        "vehicle_number": None,
        "collection_task": None,
        "collection_segments": None,
        "collection_location": None,
        "collection_date": None,
        "collection_time_period": None,
        "driving_distance": None
    }
    
    # å¸æœºå§“åæå–
    name_patterns = [r'é‡‡é›†å‘˜[ï¼š:]\s*([^ï¼Œ,\n]+)', r'å§“å[ï¼š:]\s*([^ï¼Œ,\n]+)', r'å¸æœº[ï¼š:]\s*([^ï¼Œ,\n]+)']
    for pattern in name_patterns:
        match = re.search(pattern, text)
        if match:
            result["driver_name"] = match.group(1).strip()
            break
    
    # è½¦è¾†ç¼–å·æå–
    vehicle_patterns = [r'è½¦è¾†ç¼–å·[ï¼š:]\s*([^ï¼Œ,\n]+)', r'è½¦ç‰Œ[ï¼š:]\s*([^ï¼Œ,\n]+)', r'è½¦å·[ï¼š:]\s*([^ï¼Œ,\n]+)']
    for pattern in vehicle_patterns:
        match = re.search(pattern, text)
        if match:
            result["vehicle_number"] = match.group(1).strip()
            break
    
    # é‡‡é›†ä»»åŠ¡æå–
    task_patterns = [r'é‡‡é›†ä»»åŠ¡[ï¼š:]\s*([^ï¼Œ,\n]+)', r'ä»»åŠ¡[ï¼š:]\s*([^ï¼Œ,\n]+)', r'é¡¹ç›®[ï¼š:]\s*([^ï¼Œ,\n]+)']
    for pattern in task_patterns:
        match = re.search(pattern, text)
        if match:
            result["collection_task"] = match.group(1).strip()
            break
    
    # é‡‡é›†æ®µæ•°æå–ï¼ˆæå–æ•°å­—ï¼‰
    segments_patterns = [r'é‡‡é›†æ®µæ•°[ï¼š:]\s*(\d+)', r'æ®µæ•°[ï¼š:]\s*(\d+)', r'(\d+)\s*æ®µ']
    for pattern in segments_patterns:
        match = re.search(pattern, text)
        if match:
            result["collection_segments"] = int(match.group(1))
            break
    
    # é‡‡é›†åœ°ç‚¹æå–
    location_patterns = [r'é‡‡é›†åœ°ç‚¹[ï¼š:]\s*([^ï¼Œ,\n]+)', r'åœ°ç‚¹[ï¼š:]\s*([^ï¼Œ,\n]+)', r'ä½ç½®[ï¼š:]\s*([^ï¼Œ,\n]+)']
    for pattern in location_patterns:
        match = re.search(pattern, text)
        if match:
            result["collection_location"] = match.group(1).strip()
            break
    
    # é‡‡é›†æ—¥æœŸæå–
    date_patterns = [r'é‡‡é›†æ—¥æœŸ[ï¼š:]\s*([0-9-/]+)', r'æ—¥æœŸ[ï¼š:]\s*([0-9-/]+)', r'æ—¶é—´[ï¼š:]\s*([0-9-/]+)']
    for pattern in date_patterns:
        match = re.search(pattern, text)
        if match:
            result["collection_date"] = match.group(1).strip()
            break
    
    # é‡‡é›†æ—¶æ®µæå–
    if 'ç™½å¤©' in text or 'ç™½' in text or 'ä¸Šåˆ' in text or 'ä¸‹åˆ' in text:
        result["collection_time_period"] = "ç™½å¤©"
    elif 'å¤œæ™š' in text or 'å¤œ' in text or 'æ™šä¸Š' in text:
        result["collection_time_period"] = "å¤œæ™š"
    
    # è¡Œé©¶é‡Œç¨‹æå–
    distance_patterns = [r'è¡Œé©¶é‡Œç¨‹[ï¼š:]\s*([0-9.]+)', r'é‡Œç¨‹[ï¼š:]\s*([0-9.]+)', r'([0-9.]+)\s*å…¬é‡Œ', r'è·ç¦»[ï¼š:]\s*([0-9.]+)']
    for pattern in distance_patterns:
        match = re.search(pattern, text)
        if match:
            result["driving_distance"] = float(match.group(1))
            break
    
    return result

def save_to_database(data: Dict, raw_text: str):
    """ä¿å­˜æ•°æ®åˆ°SQLiteæ•°æ®åº“"""
    conn = sqlite3.connect('driver_data.db')
    cursor = conn.cursor()
    
    cursor.execute('''
    INSERT INTO driver_reports 
    (driver_name, vehicle_number, collection_task, collection_segments, 
     collection_location, collection_date, collection_time_period, 
     driving_distance, raw_text)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', (
        data["driver_name"], data["vehicle_number"], data["collection_task"],
        data["collection_segments"], data["collection_location"], 
        data["collection_date"], data["collection_time_period"],
        data["driving_distance"], raw_text
    ))
    
    conn.commit()
    conn.close()

def process_sample_data():
    """å¤„ç†ç¤ºä¾‹æ•°æ®"""
    sample_reports = [
        """
        é‡‡é›†å‘˜ï¼šæå››
        è½¦è¾†ç¼–å·ï¼šæ²ªB67890
        é‡‡é›†ä»»åŠ¡ï¼šä¸Šæµ·é«˜é€Ÿå…¬è·¯æ•°æ®é‡‡é›†
        é‡‡é›†æ®µæ•°ï¼š8
        é‡‡é›†åœ°ç‚¹ï¼šä¸Šæµ·
        é‡‡é›†æ—¥æœŸï¼š2025-01-11
        é‡‡é›†æ—¶æ®µï¼šå¤œæ™š
        è¡Œé©¶é‡Œç¨‹ï¼š200.3å…¬é‡Œ
        """,
        
        """
        å¸æœºï¼šç‹äº”
        è½¦ç‰Œï¼šç²¤C11111
        é¡¹ç›®ï¼šå¹¿å·å¸‚åŒºæ™ºé©¾æµ‹è¯•
        æ®µæ•°ï¼š3
        ä½ç½®ï¼šå¹¿å·
        æ—¶é—´ï¼š2025-01-12
        ç™½å¤©é‡‡é›†
        è·ç¦»ï¼š85.7å…¬é‡Œ
        """,
        
        """
        å§“åï¼šèµµå…­
        è½¦å·ï¼šäº¬D22222
        ä»»åŠ¡ï¼šåŒ—äº¬ç¯è·¯é‡‡é›†ä»»åŠ¡
        é‡‡é›†äº†6æ®µ
        åœ°ç‚¹ï¼šåŒ—äº¬
        æ—¥æœŸï¼š2025-01-13
        å¤œé—´ä½œä¸š
        é‡Œç¨‹ï¼š156.8å…¬é‡Œ
        """,
        
        """
        é‡‡é›†å‘˜ï¼šé’±ä¸ƒ
        è½¦è¾†ç¼–å·ï¼šå·E33333
        é‡‡é›†ä»»åŠ¡ï¼šæˆéƒ½å¸‚æ™ºèƒ½é©¾é©¶æ•°æ®æ”¶é›†
        é‡‡é›†æ®µæ•°ï¼š4
        é‡‡é›†åœ°ç‚¹ï¼šæˆéƒ½
        é‡‡é›†æ—¥æœŸï¼š2025-01-14
        é‡‡é›†æ—¶æ®µï¼šç™½å¤©
        è¡Œé©¶é‡Œç¨‹ï¼š98.2å…¬é‡Œ
        """,
        
        """
        å¸æœºï¼šå­™å…«
        è½¦ç‰Œå·ï¼šæµ™F44444
        é‡‡é›†é¡¹ç›®ï¼šæ­å·åŸåŒºé“è·¯æµ‹è¯•
        å®Œæˆæ®µæ•°ï¼š7
        æµ‹è¯•åœ°ç‚¹ï¼šæ­å·
        æµ‹è¯•æ—¥æœŸï¼š2025-01-15
        ä¸‹åˆæ—¶æ®µ
        æ€»é‡Œç¨‹ï¼š175.6å…¬é‡Œ
        """
    ]
    
    print("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†ç¤ºä¾‹æ•°æ®...")
    
    for i, report_text in enumerate(sample_reports, 1):
        print(f"\nğŸ“Š å¤„ç†ç¬¬ {i} æ¡æ•°æ®...")
        
        # è§£ææ•°æ®
        extracted_data = extract_with_rules(report_text)
        print(f"è§£æç»“æœ: {json.dumps(extracted_data, ensure_ascii=False)}")
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        save_to_database(extracted_data, report_text.strip())
        print("âœ… æ•°æ®å·²ä¿å­˜")
    
    print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(sample_reports)} æ¡æ•°æ®")

def get_final_summary():
    """è·å–æœ€ç»ˆæ±‡æ€»"""
    conn = sqlite3.connect('driver_data.db')
    df = pd.read_sql_query("SELECT * FROM driver_reports", conn)
    conn.close()
    
    print("\nğŸ“ˆ æœ€ç»ˆæ•°æ®æ±‡æ€»:")
    print(f"ğŸ“Š æ€»æŠ¥å‘Šæ•°: {len(df)}")
    print(f"ğŸ‘¥ å¸æœºæ•°é‡: {df['driver_name'].nunique()}")
    print(f"ğŸ›£ï¸  æ€»é‡‡é›†æ®µæ•°: {df['collection_segments'].sum()}")
    print(f"ğŸš— æ€»è¡Œé©¶é‡Œç¨‹: {df['driving_distance'].sum():.1f} å…¬é‡Œ")
    
    print(f"\nğŸ“ é‡‡é›†åœ°ç‚¹åˆ†å¸ƒ:")
    for location, count in df['collection_location'].value_counts().items():
        print(f"   {location}: {count} æ¬¡")
    
    print(f"\nâ° æ—¶æ®µåˆ†å¸ƒ:")
    for period, count in df['collection_time_period'].value_counts().items():
        print(f"   {period}: {count} æ¬¡")
    
    # å¯¼å‡ºæœ€ç»ˆæ•°æ®
    filename = f"driver_reports_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    df.to_csv(filename, index=False, encoding='utf-8-sig')
    print(f"\nğŸ“¤ æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")

if __name__ == "__main__":
    process_sample_data()
    get_final_summary()